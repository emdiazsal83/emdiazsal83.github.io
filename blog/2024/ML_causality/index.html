<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Links between machine learning and causality | Emiliano Díaz Salas-Porras </title> <meta name="author" content="Emiliano Díaz Salas-Porras"> <meta name="description" content="Causality guides ML through change"> <meta name="keywords" content="machine learning, causality"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://emdiazsal83.github.io/blog/2024/ML_causality/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Emiliano</span> Díaz Salas-Porras </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Links between machine learning and causality</h1> <p class="post-meta"> Created in June 01, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/machinelearning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machinelearning</a>   <a href="/blog/tag/causality"> <i class="fa-solid fa-hashtag fa-sm"></i> causality</a>     ·   <a href="/blog/category/causality"> <i class="fa-solid fa-tag fa-sm"></i> causality</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Machine learning (ML), and statistics, is, in essence, a field dealing with estimating probability distributions from data. It is used within causal inference as a tool for learning observed probability distributions, or properties of these, to learn a DAG (causal discovery) or estimate an interventional distribution (cause-effect estimation). Since causal inference is, in effect, a language that may be used to describe the changes a system may endure and articulate how these may impact the probability distribution of the system, there are many interesting links with subfields of machine learning which deal with the problem of learning from data generated in such changing environments [Kaddour et al., 2022, Schölkopf, 2022].</p> <p>Generalisability and robustness in ML deal with learning a probability distribution from observed data that is valid for unobserved data. Insofar as any changes in the data are caused by a changing underlying generating mechanism, causality gives the language to articulate these changes and decide which parts, or factors, of the probability distribution need changing. With regard to changes resulting from differing sampling procedures, more recent developments [Bareinboim and Pearl, 2016] also provide the necessary language to reason about what aspects of the probability distribution change and which don’t.</p> <p>Similarly, co-variate shift and non-stationarity describe situations where the data distribution of subsets of observations generated at different times has changed. In the case of a co-variate shift, where the distribution of the inputs changes, knowing the underlying causal structure can help determine if we should modify our predictive models in response to this change. If the inputs correspond to the causes and outputs to effects, then the modularity of the FCM dictates that this will not influence the conditional distribution of outputs given inputs. When the prediction task is anti-causal, in the sense that inputs are effects and outputs are causes, the co-variate shift does necessitate that the prediction model is changed.</p> <p>Something similar occurs in semi-supervised learning, where complementary information about the distribution of the inputs is used in learning about the conditional distribution of outputs given inputs. This may be fruitful if the modelling is done in the anti-causal direction. However, if modularity is satisfied in the causal direction, this cannot help [Schölkopf et al., 2012].</p> <p>Transfer learning [Pan and Yang, 2010], domain-adaptation [Farahani et al., 2021], meta-learning [Vilalta and Drissi, 2002], and few/one/zero-shot learning [Wang et al., 2020] are families of methods interested in learning a probability distribution with using large amount of data generated by one distribution and then using a small amount of data generated with a changed distribution, to adapt, or update, the estimate. Again, causality can provide the language to describe these changes and the required conditions to estimate the relevant probability distributions [Rojas-Carulla et al., 2018, Magliacane et al., 2018].</p> <p>Active learning [Settles,2009] refers to the problem of choosing how to sample new data in order to improve our probability distribution estimation. If we can perform controlled experiments, the active learning prerogative of sampling new data is further extended. Causality gives us the tools to identify which interventional distributions to sample from, i.e., which experiments to conduct, to identify the underlying causal structure fully [Toth et al., 2022].</p> <p>In reinforcement learning, an agent chooses actions in a stochastic environment to maximize his expected reward. Causal inference can guide the process of knowing which actions to take to better explore (sample) the different interventional distributions implied by the FCM that governs the environment [Weichwald et al., 2022].</p> <p>In ML,latent modelling techniques, such as variational autoencoders [Kingma and Welling, 2014], generally attempt to find a sparse underlying representation, or factorization, of a high dimensional probability distribution. This is connected to causal discovery since, under certain specific modularity assumptions, the causal factorization of the joint, corresponding to the causal DAG is the simplest possible factorization [Schölkopf et al., 2021, Wang et al., 2023]. In ML, generative models, such as generative adversarial networks [Goodfellow et al., 2014] or normalizing flows [Rafajłowicz, 2020], generally attempt to describe high- dimensional structured data as a series of functions in the form of iterative transformations applied to multivariate noise, where components are mutually independent. These models effectively estimate an FCM since, as we have mentioned, an FCM can be re-expressed in terms of only independent noise variables [Monti et al., 2020, Khemakhem et al., 2020].</p> <p>Finally, hybrid and physically informed models attempt to incorporate, a priori, knowledge about the phenomenon at hand into ML algorithms which learn from data. From a causal point of view, this may be incorporated by keeping fixed, known subgraphs of the causal DAG. Alternatively, when mixed data from different environments are available, physics-style conservation restrictions may be introduced. In this case, several, possibly natural, interventions have occurred. Using the modularity assumption of FCMs, we may enforce those models corresponding to equations not intervened on remain invariant, such as is applied with [Peters et al., 2016].</p> </div> </article> <br> <hr> <br> If you found this useful, please cite this as: <blockquote> <p>Salas-Porras, Emiliano Díaz (Jun 2024). Links between machine learning and causality. https://emdiazsal83.github.io.</p> </blockquote> <p>or as a BibTeX entry:</p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">salas-porras2024links-between-machine-learning-and-causality</span><span class="p">,</span>
  <span class="na">title</span>   <span class="p">=</span> <span class="s">{Links between machine learning and causality}</span><span class="p">,</span>
  <span class="na">author</span>  <span class="p">=</span> <span class="s">{Salas-Porras, Emiliano Díaz}</span><span class="p">,</span>
  <span class="na">year</span>    <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span>   <span class="p">=</span> <span class="s">{Jun}</span><span class="p">,</span>
  <span class="na">url</span>     <span class="p">=</span> <span class="s">{https://emdiazsal83.github.io/blog/2024/ML_causality/}</span>
<span class="p">}</span>
</code></pre></div></div> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/pearlrubin/">Pearl and Rubin</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Emiliano Díaz Salas-Porras. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>